{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81bd4618",
   "metadata": {},
   "source": [
    "# KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6587e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58a09834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classifiers\n",
    "classifiers = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(tree_method='gpu_hist'), \n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Extra Trees': ExtraTreesClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d9fe168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier: KNN\n",
      "==============================\n",
      "\n",
      "Training Metrics and Times\n",
      "------------------------------\n",
      "Split Training Time (s)   Accuracy  Precision Recall    F1-score  AUC-ROC   \n",
      "1     0.6889              0.92      0.93      0.90      0.92      0.92      \n",
      "2     0.7285              0.92      0.93      0.90      0.92      0.92      \n",
      "3     0.6598              0.92      0.93      0.90      0.92      0.92      \n",
      "4     0.7415              0.92      0.93      0.90      0.92      0.92      \n",
      "5     0.7505              0.92      0.93      0.90      0.92      0.92      \n",
      "Mean  0.7138              0.92      0.93      0.90      0.92      0.92      \n",
      "\n",
      "Testing Metrics and Times\n",
      "------------------------------\n",
      "Split Testing Time (s)    Accuracy  Precision Recall    F1-score  AUC-ROC   \n",
      "1     32.3251             0.85      0.87      0.83      0.85      0.85      \n",
      "2     31.6547             0.85      0.87      0.83      0.85      0.85      \n",
      "3     31.7438             0.85      0.87      0.83      0.85      0.85      \n",
      "4     31.8520             0.86      0.87      0.83      0.85      0.86      \n",
      "5     29.8666             0.85      0.87      0.83      0.85      0.85      \n",
      "Mean  31.4884             0.85      0.87      0.83      0.85      0.85      \n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"\\nClassifier: {clf_name}\\n{'=' * 30}\")\n",
    "    \n",
    "    # Lists for training and testing metrics\n",
    "    metrics_headers = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"AUC-ROC\"]\n",
    "    \n",
    "    training_metrics, testing_metrics = [], []    \n",
    "    training_times, testing_times = [], []  \n",
    "    \n",
    "    # Initialize KFold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    #cross-validation \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train), 1):\n",
    "        \n",
    "        X_train_fold, X_test_fold = X_train.values[train_index], X_train.values[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.values[train_index], y_train.values[test_index]\n",
    "        \n",
    "        # Measure training time\n",
    "        start_time = time.time()\n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Predict on training folds and test folds\n",
    "        start_time = time.time()\n",
    "        y_pred_train = clf.predict(X_train_fold) \n",
    "        y_pred = clf.predict(X_test_fold)\n",
    "        testing_time = time.time() - start_time\n",
    "\n",
    "        # Calculate training and testing metrics\n",
    "        training_metrics_fold = [\n",
    "            accuracy_score(y_train_fold, y_pred_train),\n",
    "            precision_score(y_train_fold, y_pred_train),\n",
    "            recall_score(y_train_fold, y_pred_train),\n",
    "            f1_score(y_train_fold, y_pred_train),\n",
    "            roc_auc_score(y_train_fold, y_pred_train)\n",
    "        ]\n",
    "\n",
    "        testing_metrics_fold = [\n",
    "            accuracy_score(y_test_fold, y_pred),\n",
    "            precision_score(y_test_fold, y_pred),\n",
    "            recall_score(y_test_fold, y_pred),\n",
    "            f1_score(y_test_fold, y_pred),\n",
    "            roc_auc_score(y_test_fold, y_pred)\n",
    "        ]\n",
    "\n",
    "        # Append metrics to lists\n",
    "        training_metrics.append(training_metrics_fold)\n",
    "        testing_metrics.append(testing_metrics_fold)\n",
    "\n",
    "        training_times.append(training_time)\n",
    "        testing_times.append(testing_time)\n",
    "   \n",
    "    # Print mean metrics and times across splits\n",
    "    \n",
    "    # Training Metrics and Times\n",
    "    print(\"\\nTraining Metrics and Times\\n\" + '-' * 30)\n",
    "    print(f\"{'Split':<6}{'Training Time (s)':<20}{metrics_headers[0]:<10}{metrics_headers[1]:<10}{metrics_headers[2]:<10}{metrics_headers[3]:<10}{metrics_headers[4]:<10}\")\n",
    "    \n",
    "    for i in range(len(training_metrics)):\n",
    "        print(f\"{i + 1:<6}{training_times[i]:<20.4f}{training_metrics[i][0]:<10.2f}{training_metrics[i][1]:<10.2f}{training_metrics[i][2]:<10.2f}{training_metrics[i][3]:<10.2f}{training_metrics[i][4]:<10.2f}\")\n",
    "    print(f\"{'Mean':<6}{np.mean(training_times):<20.4f}{np.mean(training_metrics, axis=0)[0]:<10.2f}{np.mean(training_metrics, axis=0)[1]:<10.2f}{np.mean(training_metrics, axis=0)[2]:<10.2f}{np.mean(training_metrics, axis=0)[3]:<10.2f}{np.mean(training_metrics, axis=0)[4]:<10.2f}\")\n",
    "    \n",
    "    \n",
    "    # Testing Metrics and Times\n",
    "    print(\"\\nTesting Metrics and Times\\n\" + '-' * 30)\n",
    "    print(f\"{'Split':<6}{'Testing Time (s)':<20}{metrics_headers[0]:<10}{metrics_headers[1]:<10}{metrics_headers[2]:<10}{metrics_headers[3]:<10}{metrics_headers[4]:<10}\")\n",
    "    \n",
    "    for i in range(len(testing_metrics)):\n",
    "        print(f\"{i + 1:<6}{testing_times[i]:<20.4f}{testing_metrics[i][0]:<10.2f}{testing_metrics[i][1]:<10.2f}{testing_metrics[i][2]:<10.2f}{testing_metrics[i][3]:<10.2f}{testing_metrics[i][4]:<10.2f}\")\n",
    "    print(f\"{'Mean':<6}{np.mean(testing_times):<20.4f}{np.mean(testing_metrics, axis=0)[0]:<10.2f}{np.mean(testing_metrics, axis=0)[1]:<10.2f}{np.mean(testing_metrics, axis=0)[2]:<10.2f}{np.mean(testing_metrics, axis=0)[3]:<10.2f}{np.mean(testing_metrics, axis=0)[4]:<10.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
