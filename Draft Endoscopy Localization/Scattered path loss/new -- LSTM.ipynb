{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17f330",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/thebrownviking20/intro-to-recurrent-neural-networks-lstm-gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d21e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAABhCAYAAACwNehEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAB2UlEQVR4nO3ZMW4TURhG0QlCms5eaBYxW4IlpE5BGQmhLIAKu5rupaFFd2xpMDbn1K/49RVXHvlpjDEmAP7o060PAPjXCSVAEEqAIJQAQSgBglACBKEECEIJEIQSIHze+vDnr5c973hIr+e3W59wl779eL/1CXfn9e37rU+4S1+fv2x65xclQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAcrYYF3XsSzLWNd1y3N+s9vlbHYdu+3raYwxKqbn83k6Ho/T6XSaDofD3+j3Q7Db5Wx2Hbvty6c3QBBKgCCUAGFTKOd5npZlmeZ53vueh2K3y9nsOnbb16Y/cwD+Zz69AYJQAgShBAgfqFVTywk7IEQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 400x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "colors_nude = ['#E9EFC0','#B4E197','#83BD75','#4E944F'] #if wandring why greens ?to reinforce the emotion (prediction dollar$)\n",
    "sns.palplot(sns.color_palette(colors_nude))\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "# Set Style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.metrics import  mean_squared_error ,r2_score , explained_variance_score\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV , learning_curve\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('Scattered path loss of 48 sensors for 2443 positions.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.267633</td>\n",
       "      <td>131.597806</td>\n",
       "      <td>81.831203</td>\n",
       "      <td>108.480113</td>\n",
       "      <td>126.401200</td>\n",
       "      <td>153.464898</td>\n",
       "      <td>112.979443</td>\n",
       "      <td>138.850280</td>\n",
       "      <td>95.879983</td>\n",
       "      <td>120.538335</td>\n",
       "      <td>...</td>\n",
       "      <td>109.733925</td>\n",
       "      <td>122.659778</td>\n",
       "      <td>95.395578</td>\n",
       "      <td>130.490611</td>\n",
       "      <td>73.119448</td>\n",
       "      <td>121.722946</td>\n",
       "      <td>104.559876</td>\n",
       "      <td>137.225660</td>\n",
       "      <td>91.041703</td>\n",
       "      <td>127.652224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91.665371</td>\n",
       "      <td>134.314718</td>\n",
       "      <td>83.926980</td>\n",
       "      <td>126.167508</td>\n",
       "      <td>127.048010</td>\n",
       "      <td>147.329908</td>\n",
       "      <td>113.967891</td>\n",
       "      <td>144.590411</td>\n",
       "      <td>97.747726</td>\n",
       "      <td>127.941590</td>\n",
       "      <td>...</td>\n",
       "      <td>113.915353</td>\n",
       "      <td>123.190051</td>\n",
       "      <td>95.157075</td>\n",
       "      <td>127.762477</td>\n",
       "      <td>66.005689</td>\n",
       "      <td>115.881671</td>\n",
       "      <td>107.128477</td>\n",
       "      <td>140.352729</td>\n",
       "      <td>86.947794</td>\n",
       "      <td>119.210396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.052816</td>\n",
       "      <td>132.300121</td>\n",
       "      <td>76.009308</td>\n",
       "      <td>116.964033</td>\n",
       "      <td>132.173743</td>\n",
       "      <td>143.051777</td>\n",
       "      <td>115.162722</td>\n",
       "      <td>137.676604</td>\n",
       "      <td>102.738553</td>\n",
       "      <td>122.522861</td>\n",
       "      <td>...</td>\n",
       "      <td>112.052375</td>\n",
       "      <td>117.562515</td>\n",
       "      <td>99.313642</td>\n",
       "      <td>128.192048</td>\n",
       "      <td>75.164417</td>\n",
       "      <td>116.706805</td>\n",
       "      <td>112.276377</td>\n",
       "      <td>129.772121</td>\n",
       "      <td>88.276306</td>\n",
       "      <td>117.740004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.053301</td>\n",
       "      <td>127.103974</td>\n",
       "      <td>84.735175</td>\n",
       "      <td>115.929306</td>\n",
       "      <td>118.353146</td>\n",
       "      <td>149.874228</td>\n",
       "      <td>106.017232</td>\n",
       "      <td>134.139507</td>\n",
       "      <td>98.226181</td>\n",
       "      <td>122.213773</td>\n",
       "      <td>...</td>\n",
       "      <td>108.861984</td>\n",
       "      <td>129.042510</td>\n",
       "      <td>98.180222</td>\n",
       "      <td>129.344039</td>\n",
       "      <td>66.522773</td>\n",
       "      <td>117.580686</td>\n",
       "      <td>107.813133</td>\n",
       "      <td>134.786828</td>\n",
       "      <td>91.081817</td>\n",
       "      <td>118.908161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108.955215</td>\n",
       "      <td>128.747209</td>\n",
       "      <td>82.213517</td>\n",
       "      <td>116.666273</td>\n",
       "      <td>125.771908</td>\n",
       "      <td>153.445316</td>\n",
       "      <td>111.663266</td>\n",
       "      <td>140.358840</td>\n",
       "      <td>96.138273</td>\n",
       "      <td>128.801601</td>\n",
       "      <td>...</td>\n",
       "      <td>108.706859</td>\n",
       "      <td>119.970422</td>\n",
       "      <td>100.514277</td>\n",
       "      <td>126.900903</td>\n",
       "      <td>71.984768</td>\n",
       "      <td>110.931963</td>\n",
       "      <td>113.277748</td>\n",
       "      <td>139.563546</td>\n",
       "      <td>92.386548</td>\n",
       "      <td>129.117372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>128.179344</td>\n",
       "      <td>114.641972</td>\n",
       "      <td>105.710144</td>\n",
       "      <td>88.287079</td>\n",
       "      <td>149.165563</td>\n",
       "      <td>137.537974</td>\n",
       "      <td>133.750673</td>\n",
       "      <td>112.015302</td>\n",
       "      <td>120.576864</td>\n",
       "      <td>112.474493</td>\n",
       "      <td>...</td>\n",
       "      <td>119.309378</td>\n",
       "      <td>112.129281</td>\n",
       "      <td>133.167988</td>\n",
       "      <td>114.383990</td>\n",
       "      <td>102.902100</td>\n",
       "      <td>74.953746</td>\n",
       "      <td>136.775728</td>\n",
       "      <td>135.511864</td>\n",
       "      <td>113.860294</td>\n",
       "      <td>97.289917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>126.365931</td>\n",
       "      <td>110.972446</td>\n",
       "      <td>103.198207</td>\n",
       "      <td>73.414657</td>\n",
       "      <td>146.420909</td>\n",
       "      <td>140.802299</td>\n",
       "      <td>136.087553</td>\n",
       "      <td>119.668856</td>\n",
       "      <td>117.611405</td>\n",
       "      <td>97.729138</td>\n",
       "      <td>...</td>\n",
       "      <td>119.776043</td>\n",
       "      <td>109.341785</td>\n",
       "      <td>134.167797</td>\n",
       "      <td>108.758001</td>\n",
       "      <td>97.232046</td>\n",
       "      <td>76.553890</td>\n",
       "      <td>131.527636</td>\n",
       "      <td>120.620501</td>\n",
       "      <td>114.793561</td>\n",
       "      <td>86.316080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>124.285145</td>\n",
       "      <td>103.360797</td>\n",
       "      <td>109.290753</td>\n",
       "      <td>79.003261</td>\n",
       "      <td>151.453751</td>\n",
       "      <td>138.577223</td>\n",
       "      <td>133.219135</td>\n",
       "      <td>111.313822</td>\n",
       "      <td>121.482318</td>\n",
       "      <td>115.272484</td>\n",
       "      <td>...</td>\n",
       "      <td>124.257271</td>\n",
       "      <td>108.008908</td>\n",
       "      <td>124.793498</td>\n",
       "      <td>110.650887</td>\n",
       "      <td>110.008857</td>\n",
       "      <td>71.785029</td>\n",
       "      <td>141.782071</td>\n",
       "      <td>125.802032</td>\n",
       "      <td>113.221141</td>\n",
       "      <td>91.163433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>128.455467</td>\n",
       "      <td>113.305564</td>\n",
       "      <td>120.534195</td>\n",
       "      <td>70.567774</td>\n",
       "      <td>150.202237</td>\n",
       "      <td>147.104822</td>\n",
       "      <td>128.145483</td>\n",
       "      <td>115.972568</td>\n",
       "      <td>118.499662</td>\n",
       "      <td>104.549275</td>\n",
       "      <td>...</td>\n",
       "      <td>125.544587</td>\n",
       "      <td>114.946916</td>\n",
       "      <td>128.766695</td>\n",
       "      <td>114.402412</td>\n",
       "      <td>100.797834</td>\n",
       "      <td>77.919668</td>\n",
       "      <td>139.414337</td>\n",
       "      <td>117.483786</td>\n",
       "      <td>123.049769</td>\n",
       "      <td>91.451389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>122.108331</td>\n",
       "      <td>117.023437</td>\n",
       "      <td>102.527909</td>\n",
       "      <td>87.494457</td>\n",
       "      <td>151.737028</td>\n",
       "      <td>140.752720</td>\n",
       "      <td>139.551852</td>\n",
       "      <td>113.287240</td>\n",
       "      <td>119.649711</td>\n",
       "      <td>114.469436</td>\n",
       "      <td>...</td>\n",
       "      <td>120.001152</td>\n",
       "      <td>109.766753</td>\n",
       "      <td>125.244051</td>\n",
       "      <td>114.664490</td>\n",
       "      <td>110.627432</td>\n",
       "      <td>76.722995</td>\n",
       "      <td>138.251458</td>\n",
       "      <td>128.808403</td>\n",
       "      <td>123.226069</td>\n",
       "      <td>96.901824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0     103.267633  131.597806   81.831203  108.480113  126.401200  153.464898   \n",
       "1      91.665371  134.314718   83.926980  126.167508  127.048010  147.329908   \n",
       "2     108.052816  132.300121   76.009308  116.964033  132.173743  143.051777   \n",
       "3     101.053301  127.103974   84.735175  115.929306  118.353146  149.874228   \n",
       "4     108.955215  128.747209   82.213517  116.666273  125.771908  153.445316   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  128.179344  114.641972  105.710144   88.287079  149.165563  137.537974   \n",
       "2439  126.365931  110.972446  103.198207   73.414657  146.420909  140.802299   \n",
       "2440  124.285145  103.360797  109.290753   79.003261  151.453751  138.577223   \n",
       "2441  128.455467  113.305564  120.534195   70.567774  150.202237  147.104822   \n",
       "2442  122.108331  117.023437  102.527909   87.494457  151.737028  140.752720   \n",
       "\n",
       "              6           7           8           9   ...          38  \\\n",
       "0     112.979443  138.850280   95.879983  120.538335  ...  109.733925   \n",
       "1     113.967891  144.590411   97.747726  127.941590  ...  113.915353   \n",
       "2     115.162722  137.676604  102.738553  122.522861  ...  112.052375   \n",
       "3     106.017232  134.139507   98.226181  122.213773  ...  108.861984   \n",
       "4     111.663266  140.358840   96.138273  128.801601  ...  108.706859   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  133.750673  112.015302  120.576864  112.474493  ...  119.309378   \n",
       "2439  136.087553  119.668856  117.611405   97.729138  ...  119.776043   \n",
       "2440  133.219135  111.313822  121.482318  115.272484  ...  124.257271   \n",
       "2441  128.145483  115.972568  118.499662  104.549275  ...  125.544587   \n",
       "2442  139.551852  113.287240  119.649711  114.469436  ...  120.001152   \n",
       "\n",
       "              39          40          41          42          43          44  \\\n",
       "0     122.659778   95.395578  130.490611   73.119448  121.722946  104.559876   \n",
       "1     123.190051   95.157075  127.762477   66.005689  115.881671  107.128477   \n",
       "2     117.562515   99.313642  128.192048   75.164417  116.706805  112.276377   \n",
       "3     129.042510   98.180222  129.344039   66.522773  117.580686  107.813133   \n",
       "4     119.970422  100.514277  126.900903   71.984768  110.931963  113.277748   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  112.129281  133.167988  114.383990  102.902100   74.953746  136.775728   \n",
       "2439  109.341785  134.167797  108.758001   97.232046   76.553890  131.527636   \n",
       "2440  108.008908  124.793498  110.650887  110.008857   71.785029  141.782071   \n",
       "2441  114.946916  128.766695  114.402412  100.797834   77.919668  139.414337   \n",
       "2442  109.766753  125.244051  114.664490  110.627432   76.722995  138.251458   \n",
       "\n",
       "              45          46          47  \n",
       "0     137.225660   91.041703  127.652224  \n",
       "1     140.352729   86.947794  119.210396  \n",
       "2     129.772121   88.276306  117.740004  \n",
       "3     134.786828   91.081817  118.908161  \n",
       "4     139.563546   92.386548  129.117372  \n",
       "...          ...         ...         ...  \n",
       "2438  135.511864  113.860294   97.289917  \n",
       "2439  120.620501  114.793561   86.316080  \n",
       "2440  125.802032  113.221141   91.163433  \n",
       "2441  117.483786  123.049769   91.451389  \n",
       "2442  128.808403  123.226069   96.901824  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real x-y-z positions of 2443 locations.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.267633</td>\n",
       "      <td>131.597806</td>\n",
       "      <td>81.831203</td>\n",
       "      <td>108.480113</td>\n",
       "      <td>126.401200</td>\n",
       "      <td>153.464898</td>\n",
       "      <td>112.979443</td>\n",
       "      <td>138.850280</td>\n",
       "      <td>95.879983</td>\n",
       "      <td>120.538335</td>\n",
       "      <td>...</td>\n",
       "      <td>109.733925</td>\n",
       "      <td>122.659778</td>\n",
       "      <td>95.395578</td>\n",
       "      <td>130.490611</td>\n",
       "      <td>73.119448</td>\n",
       "      <td>121.722946</td>\n",
       "      <td>104.559876</td>\n",
       "      <td>137.225660</td>\n",
       "      <td>91.041703</td>\n",
       "      <td>127.652224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91.665371</td>\n",
       "      <td>134.314718</td>\n",
       "      <td>83.926980</td>\n",
       "      <td>126.167508</td>\n",
       "      <td>127.048010</td>\n",
       "      <td>147.329908</td>\n",
       "      <td>113.967891</td>\n",
       "      <td>144.590411</td>\n",
       "      <td>97.747726</td>\n",
       "      <td>127.941590</td>\n",
       "      <td>...</td>\n",
       "      <td>113.915353</td>\n",
       "      <td>123.190051</td>\n",
       "      <td>95.157075</td>\n",
       "      <td>127.762477</td>\n",
       "      <td>66.005689</td>\n",
       "      <td>115.881671</td>\n",
       "      <td>107.128477</td>\n",
       "      <td>140.352729</td>\n",
       "      <td>86.947794</td>\n",
       "      <td>119.210396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.052816</td>\n",
       "      <td>132.300121</td>\n",
       "      <td>76.009308</td>\n",
       "      <td>116.964033</td>\n",
       "      <td>132.173743</td>\n",
       "      <td>143.051777</td>\n",
       "      <td>115.162722</td>\n",
       "      <td>137.676604</td>\n",
       "      <td>102.738553</td>\n",
       "      <td>122.522861</td>\n",
       "      <td>...</td>\n",
       "      <td>112.052375</td>\n",
       "      <td>117.562515</td>\n",
       "      <td>99.313642</td>\n",
       "      <td>128.192048</td>\n",
       "      <td>75.164417</td>\n",
       "      <td>116.706805</td>\n",
       "      <td>112.276377</td>\n",
       "      <td>129.772121</td>\n",
       "      <td>88.276306</td>\n",
       "      <td>117.740004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.053301</td>\n",
       "      <td>127.103974</td>\n",
       "      <td>84.735175</td>\n",
       "      <td>115.929306</td>\n",
       "      <td>118.353146</td>\n",
       "      <td>149.874228</td>\n",
       "      <td>106.017232</td>\n",
       "      <td>134.139507</td>\n",
       "      <td>98.226181</td>\n",
       "      <td>122.213773</td>\n",
       "      <td>...</td>\n",
       "      <td>108.861984</td>\n",
       "      <td>129.042510</td>\n",
       "      <td>98.180222</td>\n",
       "      <td>129.344039</td>\n",
       "      <td>66.522773</td>\n",
       "      <td>117.580686</td>\n",
       "      <td>107.813133</td>\n",
       "      <td>134.786828</td>\n",
       "      <td>91.081817</td>\n",
       "      <td>118.908161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108.955215</td>\n",
       "      <td>128.747209</td>\n",
       "      <td>82.213517</td>\n",
       "      <td>116.666273</td>\n",
       "      <td>125.771908</td>\n",
       "      <td>153.445316</td>\n",
       "      <td>111.663266</td>\n",
       "      <td>140.358840</td>\n",
       "      <td>96.138273</td>\n",
       "      <td>128.801601</td>\n",
       "      <td>...</td>\n",
       "      <td>108.706859</td>\n",
       "      <td>119.970422</td>\n",
       "      <td>100.514277</td>\n",
       "      <td>126.900903</td>\n",
       "      <td>71.984768</td>\n",
       "      <td>110.931963</td>\n",
       "      <td>113.277748</td>\n",
       "      <td>139.563546</td>\n",
       "      <td>92.386548</td>\n",
       "      <td>129.117372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>128.179344</td>\n",
       "      <td>114.641972</td>\n",
       "      <td>105.710144</td>\n",
       "      <td>88.287079</td>\n",
       "      <td>149.165563</td>\n",
       "      <td>137.537974</td>\n",
       "      <td>133.750673</td>\n",
       "      <td>112.015302</td>\n",
       "      <td>120.576864</td>\n",
       "      <td>112.474493</td>\n",
       "      <td>...</td>\n",
       "      <td>119.309378</td>\n",
       "      <td>112.129281</td>\n",
       "      <td>133.167988</td>\n",
       "      <td>114.383990</td>\n",
       "      <td>102.902100</td>\n",
       "      <td>74.953746</td>\n",
       "      <td>136.775728</td>\n",
       "      <td>135.511864</td>\n",
       "      <td>113.860294</td>\n",
       "      <td>97.289917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>126.365931</td>\n",
       "      <td>110.972446</td>\n",
       "      <td>103.198207</td>\n",
       "      <td>73.414657</td>\n",
       "      <td>146.420909</td>\n",
       "      <td>140.802299</td>\n",
       "      <td>136.087553</td>\n",
       "      <td>119.668856</td>\n",
       "      <td>117.611405</td>\n",
       "      <td>97.729138</td>\n",
       "      <td>...</td>\n",
       "      <td>119.776043</td>\n",
       "      <td>109.341785</td>\n",
       "      <td>134.167797</td>\n",
       "      <td>108.758001</td>\n",
       "      <td>97.232046</td>\n",
       "      <td>76.553890</td>\n",
       "      <td>131.527636</td>\n",
       "      <td>120.620501</td>\n",
       "      <td>114.793561</td>\n",
       "      <td>86.316080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>124.285145</td>\n",
       "      <td>103.360797</td>\n",
       "      <td>109.290753</td>\n",
       "      <td>79.003261</td>\n",
       "      <td>151.453751</td>\n",
       "      <td>138.577223</td>\n",
       "      <td>133.219135</td>\n",
       "      <td>111.313822</td>\n",
       "      <td>121.482318</td>\n",
       "      <td>115.272484</td>\n",
       "      <td>...</td>\n",
       "      <td>124.257271</td>\n",
       "      <td>108.008908</td>\n",
       "      <td>124.793498</td>\n",
       "      <td>110.650887</td>\n",
       "      <td>110.008857</td>\n",
       "      <td>71.785029</td>\n",
       "      <td>141.782071</td>\n",
       "      <td>125.802032</td>\n",
       "      <td>113.221141</td>\n",
       "      <td>91.163433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>128.455467</td>\n",
       "      <td>113.305564</td>\n",
       "      <td>120.534195</td>\n",
       "      <td>70.567774</td>\n",
       "      <td>150.202237</td>\n",
       "      <td>147.104822</td>\n",
       "      <td>128.145483</td>\n",
       "      <td>115.972568</td>\n",
       "      <td>118.499662</td>\n",
       "      <td>104.549275</td>\n",
       "      <td>...</td>\n",
       "      <td>125.544587</td>\n",
       "      <td>114.946916</td>\n",
       "      <td>128.766695</td>\n",
       "      <td>114.402412</td>\n",
       "      <td>100.797834</td>\n",
       "      <td>77.919668</td>\n",
       "      <td>139.414337</td>\n",
       "      <td>117.483786</td>\n",
       "      <td>123.049769</td>\n",
       "      <td>91.451389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>122.108331</td>\n",
       "      <td>117.023437</td>\n",
       "      <td>102.527909</td>\n",
       "      <td>87.494457</td>\n",
       "      <td>151.737028</td>\n",
       "      <td>140.752720</td>\n",
       "      <td>139.551852</td>\n",
       "      <td>113.287240</td>\n",
       "      <td>119.649711</td>\n",
       "      <td>114.469436</td>\n",
       "      <td>...</td>\n",
       "      <td>120.001152</td>\n",
       "      <td>109.766753</td>\n",
       "      <td>125.244051</td>\n",
       "      <td>114.664490</td>\n",
       "      <td>110.627432</td>\n",
       "      <td>76.722995</td>\n",
       "      <td>138.251458</td>\n",
       "      <td>128.808403</td>\n",
       "      <td>123.226069</td>\n",
       "      <td>96.901824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     103.267633  131.597806   81.831203  108.480113  126.401200  153.464898   \n",
       "1      91.665371  134.314718   83.926980  126.167508  127.048010  147.329908   \n",
       "2     108.052816  132.300121   76.009308  116.964033  132.173743  143.051777   \n",
       "3     101.053301  127.103974   84.735175  115.929306  118.353146  149.874228   \n",
       "4     108.955215  128.747209   82.213517  116.666273  125.771908  153.445316   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  128.179344  114.641972  105.710144   88.287079  149.165563  137.537974   \n",
       "2439  126.365931  110.972446  103.198207   73.414657  146.420909  140.802299   \n",
       "2440  124.285145  103.360797  109.290753   79.003261  151.453751  138.577223   \n",
       "2441  128.455467  113.305564  120.534195   70.567774  150.202237  147.104822   \n",
       "2442  122.108331  117.023437  102.527909   87.494457  151.737028  140.752720   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...    sensor39  \\\n",
       "0     112.979443  138.850280   95.879983  120.538335  ...  109.733925   \n",
       "1     113.967891  144.590411   97.747726  127.941590  ...  113.915353   \n",
       "2     115.162722  137.676604  102.738553  122.522861  ...  112.052375   \n",
       "3     106.017232  134.139507   98.226181  122.213773  ...  108.861984   \n",
       "4     111.663266  140.358840   96.138273  128.801601  ...  108.706859   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  133.750673  112.015302  120.576864  112.474493  ...  119.309378   \n",
       "2439  136.087553  119.668856  117.611405   97.729138  ...  119.776043   \n",
       "2440  133.219135  111.313822  121.482318  115.272484  ...  124.257271   \n",
       "2441  128.145483  115.972568  118.499662  104.549275  ...  125.544587   \n",
       "2442  139.551852  113.287240  119.649711  114.469436  ...  120.001152   \n",
       "\n",
       "        sensor40    sensor41    sensor42    sensor43    sensor44    sensor45  \\\n",
       "0     122.659778   95.395578  130.490611   73.119448  121.722946  104.559876   \n",
       "1     123.190051   95.157075  127.762477   66.005689  115.881671  107.128477   \n",
       "2     117.562515   99.313642  128.192048   75.164417  116.706805  112.276377   \n",
       "3     129.042510   98.180222  129.344039   66.522773  117.580686  107.813133   \n",
       "4     119.970422  100.514277  126.900903   71.984768  110.931963  113.277748   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  112.129281  133.167988  114.383990  102.902100   74.953746  136.775728   \n",
       "2439  109.341785  134.167797  108.758001   97.232046   76.553890  131.527636   \n",
       "2440  108.008908  124.793498  110.650887  110.008857   71.785029  141.782071   \n",
       "2441  114.946916  128.766695  114.402412  100.797834   77.919668  139.414337   \n",
       "2442  109.766753  125.244051  114.664490  110.627432   76.722995  138.251458   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     137.225660   91.041703  127.652224  \n",
       "1     140.352729   86.947794  119.210396  \n",
       "2     129.772121   88.276306  117.740004  \n",
       "3     134.786828   91.081817  118.908161  \n",
       "4     139.563546   92.386548  129.117372  \n",
       "...          ...         ...         ...  \n",
       "2438  135.511864  113.860294   97.289917  \n",
       "2439  120.620501  114.793561   86.316080  \n",
       "2440  125.802032  113.221141   91.163433  \n",
       "2441  117.483786  123.049769   91.451389  \n",
       "2442  128.808403  123.226069   96.901824  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['PosX', 'PosY', 'PosZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PosX</th>\n",
       "      <th>PosY</th>\n",
       "      <th>PosZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PosX       PosY   PosZ\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e000bcc",
   "metadata": {},
   "source": [
    "# Concatenating Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abe21859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "      <th>PosX</th>\n",
       "      <th>PosY</th>\n",
       "      <th>PosZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.267633</td>\n",
       "      <td>131.597806</td>\n",
       "      <td>81.831203</td>\n",
       "      <td>108.480113</td>\n",
       "      <td>126.401200</td>\n",
       "      <td>153.464898</td>\n",
       "      <td>112.979443</td>\n",
       "      <td>138.850280</td>\n",
       "      <td>95.879983</td>\n",
       "      <td>120.538335</td>\n",
       "      <td>...</td>\n",
       "      <td>130.490611</td>\n",
       "      <td>73.119448</td>\n",
       "      <td>121.722946</td>\n",
       "      <td>104.559876</td>\n",
       "      <td>137.225660</td>\n",
       "      <td>91.041703</td>\n",
       "      <td>127.652224</td>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91.665371</td>\n",
       "      <td>134.314718</td>\n",
       "      <td>83.926980</td>\n",
       "      <td>126.167508</td>\n",
       "      <td>127.048010</td>\n",
       "      <td>147.329908</td>\n",
       "      <td>113.967891</td>\n",
       "      <td>144.590411</td>\n",
       "      <td>97.747726</td>\n",
       "      <td>127.941590</td>\n",
       "      <td>...</td>\n",
       "      <td>127.762477</td>\n",
       "      <td>66.005689</td>\n",
       "      <td>115.881671</td>\n",
       "      <td>107.128477</td>\n",
       "      <td>140.352729</td>\n",
       "      <td>86.947794</td>\n",
       "      <td>119.210396</td>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.052816</td>\n",
       "      <td>132.300121</td>\n",
       "      <td>76.009308</td>\n",
       "      <td>116.964033</td>\n",
       "      <td>132.173743</td>\n",
       "      <td>143.051777</td>\n",
       "      <td>115.162722</td>\n",
       "      <td>137.676604</td>\n",
       "      <td>102.738553</td>\n",
       "      <td>122.522861</td>\n",
       "      <td>...</td>\n",
       "      <td>128.192048</td>\n",
       "      <td>75.164417</td>\n",
       "      <td>116.706805</td>\n",
       "      <td>112.276377</td>\n",
       "      <td>129.772121</td>\n",
       "      <td>88.276306</td>\n",
       "      <td>117.740004</td>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.053301</td>\n",
       "      <td>127.103974</td>\n",
       "      <td>84.735175</td>\n",
       "      <td>115.929306</td>\n",
       "      <td>118.353146</td>\n",
       "      <td>149.874228</td>\n",
       "      <td>106.017232</td>\n",
       "      <td>134.139507</td>\n",
       "      <td>98.226181</td>\n",
       "      <td>122.213773</td>\n",
       "      <td>...</td>\n",
       "      <td>129.344039</td>\n",
       "      <td>66.522773</td>\n",
       "      <td>117.580686</td>\n",
       "      <td>107.813133</td>\n",
       "      <td>134.786828</td>\n",
       "      <td>91.081817</td>\n",
       "      <td>118.908161</td>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108.955215</td>\n",
       "      <td>128.747209</td>\n",
       "      <td>82.213517</td>\n",
       "      <td>116.666273</td>\n",
       "      <td>125.771908</td>\n",
       "      <td>153.445316</td>\n",
       "      <td>111.663266</td>\n",
       "      <td>140.358840</td>\n",
       "      <td>96.138273</td>\n",
       "      <td>128.801601</td>\n",
       "      <td>...</td>\n",
       "      <td>126.900903</td>\n",
       "      <td>71.984768</td>\n",
       "      <td>110.931963</td>\n",
       "      <td>113.277748</td>\n",
       "      <td>139.563546</td>\n",
       "      <td>92.386548</td>\n",
       "      <td>129.117372</td>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>128.179344</td>\n",
       "      <td>114.641972</td>\n",
       "      <td>105.710144</td>\n",
       "      <td>88.287079</td>\n",
       "      <td>149.165563</td>\n",
       "      <td>137.537974</td>\n",
       "      <td>133.750673</td>\n",
       "      <td>112.015302</td>\n",
       "      <td>120.576864</td>\n",
       "      <td>112.474493</td>\n",
       "      <td>...</td>\n",
       "      <td>114.383990</td>\n",
       "      <td>102.902100</td>\n",
       "      <td>74.953746</td>\n",
       "      <td>136.775728</td>\n",
       "      <td>135.511864</td>\n",
       "      <td>113.860294</td>\n",
       "      <td>97.289917</td>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>126.365931</td>\n",
       "      <td>110.972446</td>\n",
       "      <td>103.198207</td>\n",
       "      <td>73.414657</td>\n",
       "      <td>146.420909</td>\n",
       "      <td>140.802299</td>\n",
       "      <td>136.087553</td>\n",
       "      <td>119.668856</td>\n",
       "      <td>117.611405</td>\n",
       "      <td>97.729138</td>\n",
       "      <td>...</td>\n",
       "      <td>108.758001</td>\n",
       "      <td>97.232046</td>\n",
       "      <td>76.553890</td>\n",
       "      <td>131.527636</td>\n",
       "      <td>120.620501</td>\n",
       "      <td>114.793561</td>\n",
       "      <td>86.316080</td>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>124.285145</td>\n",
       "      <td>103.360797</td>\n",
       "      <td>109.290753</td>\n",
       "      <td>79.003261</td>\n",
       "      <td>151.453751</td>\n",
       "      <td>138.577223</td>\n",
       "      <td>133.219135</td>\n",
       "      <td>111.313822</td>\n",
       "      <td>121.482318</td>\n",
       "      <td>115.272484</td>\n",
       "      <td>...</td>\n",
       "      <td>110.650887</td>\n",
       "      <td>110.008857</td>\n",
       "      <td>71.785029</td>\n",
       "      <td>141.782071</td>\n",
       "      <td>125.802032</td>\n",
       "      <td>113.221141</td>\n",
       "      <td>91.163433</td>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>128.455467</td>\n",
       "      <td>113.305564</td>\n",
       "      <td>120.534195</td>\n",
       "      <td>70.567774</td>\n",
       "      <td>150.202237</td>\n",
       "      <td>147.104822</td>\n",
       "      <td>128.145483</td>\n",
       "      <td>115.972568</td>\n",
       "      <td>118.499662</td>\n",
       "      <td>104.549275</td>\n",
       "      <td>...</td>\n",
       "      <td>114.402412</td>\n",
       "      <td>100.797834</td>\n",
       "      <td>77.919668</td>\n",
       "      <td>139.414337</td>\n",
       "      <td>117.483786</td>\n",
       "      <td>123.049769</td>\n",
       "      <td>91.451389</td>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>122.108331</td>\n",
       "      <td>117.023437</td>\n",
       "      <td>102.527909</td>\n",
       "      <td>87.494457</td>\n",
       "      <td>151.737028</td>\n",
       "      <td>140.752720</td>\n",
       "      <td>139.551852</td>\n",
       "      <td>113.287240</td>\n",
       "      <td>119.649711</td>\n",
       "      <td>114.469436</td>\n",
       "      <td>...</td>\n",
       "      <td>114.664490</td>\n",
       "      <td>110.627432</td>\n",
       "      <td>76.722995</td>\n",
       "      <td>138.251458</td>\n",
       "      <td>128.808403</td>\n",
       "      <td>123.226069</td>\n",
       "      <td>96.901824</td>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     103.267633  131.597806   81.831203  108.480113  126.401200  153.464898   \n",
       "1      91.665371  134.314718   83.926980  126.167508  127.048010  147.329908   \n",
       "2     108.052816  132.300121   76.009308  116.964033  132.173743  143.051777   \n",
       "3     101.053301  127.103974   84.735175  115.929306  118.353146  149.874228   \n",
       "4     108.955215  128.747209   82.213517  116.666273  125.771908  153.445316   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  128.179344  114.641972  105.710144   88.287079  149.165563  137.537974   \n",
       "2439  126.365931  110.972446  103.198207   73.414657  146.420909  140.802299   \n",
       "2440  124.285145  103.360797  109.290753   79.003261  151.453751  138.577223   \n",
       "2441  128.455467  113.305564  120.534195   70.567774  150.202237  147.104822   \n",
       "2442  122.108331  117.023437  102.527909   87.494457  151.737028  140.752720   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...    sensor42  \\\n",
       "0     112.979443  138.850280   95.879983  120.538335  ...  130.490611   \n",
       "1     113.967891  144.590411   97.747726  127.941590  ...  127.762477   \n",
       "2     115.162722  137.676604  102.738553  122.522861  ...  128.192048   \n",
       "3     106.017232  134.139507   98.226181  122.213773  ...  129.344039   \n",
       "4     111.663266  140.358840   96.138273  128.801601  ...  126.900903   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  133.750673  112.015302  120.576864  112.474493  ...  114.383990   \n",
       "2439  136.087553  119.668856  117.611405   97.729138  ...  108.758001   \n",
       "2440  133.219135  111.313822  121.482318  115.272484  ...  110.650887   \n",
       "2441  128.145483  115.972568  118.499662  104.549275  ...  114.402412   \n",
       "2442  139.551852  113.287240  119.649711  114.469436  ...  114.664490   \n",
       "\n",
       "        sensor43    sensor44    sensor45    sensor46    sensor47    sensor48  \\\n",
       "0      73.119448  121.722946  104.559876  137.225660   91.041703  127.652224   \n",
       "1      66.005689  115.881671  107.128477  140.352729   86.947794  119.210396   \n",
       "2      75.164417  116.706805  112.276377  129.772121   88.276306  117.740004   \n",
       "3      66.522773  117.580686  107.813133  134.786828   91.081817  118.908161   \n",
       "4      71.984768  110.931963  113.277748  139.563546   92.386548  129.117372   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  102.902100   74.953746  136.775728  135.511864  113.860294   97.289917   \n",
       "2439   97.232046   76.553890  131.527636  120.620501  114.793561   86.316080   \n",
       "2440  110.008857   71.785029  141.782071  125.802032  113.221141   91.163433   \n",
       "2441  100.797834   77.919668  139.414337  117.483786  123.049769   91.451389   \n",
       "2442  110.627432   76.722995  138.251458  128.808403  123.226069   96.901824   \n",
       "\n",
       "           PosX       PosY   PosZ  \n",
       "0    -45.581275  30.239368 -60.00  \n",
       "1    -45.188830  30.181623 -59.96  \n",
       "2    -44.791865  30.131806 -59.92  \n",
       "3    -44.390422  30.089935 -59.88  \n",
       "4    -43.984540  30.056029 -59.84  \n",
       "...         ...        ...    ...  \n",
       "2438 -59.939858  51.788725  37.52  \n",
       "2439 -59.963718  51.389997  37.56  \n",
       "2440 -59.981583  50.990713  37.60  \n",
       "2441 -59.993448  50.591032  37.64  \n",
       "2442 -59.999315  50.191116  37.68  \n",
       "\n",
       "[2443 rows x 51 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.concat([sensors_data, position_data], axis = 1)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eb3a91",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "619570db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "      <th>PosX</th>\n",
       "      <th>PosY</th>\n",
       "      <th>PosZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>118.426550</td>\n",
       "      <td>132.352497</td>\n",
       "      <td>89.567949</td>\n",
       "      <td>96.506083</td>\n",
       "      <td>136.600493</td>\n",
       "      <td>155.498352</td>\n",
       "      <td>110.825086</td>\n",
       "      <td>124.818256</td>\n",
       "      <td>118.123353</td>\n",
       "      <td>121.818280</td>\n",
       "      <td>...</td>\n",
       "      <td>124.104267</td>\n",
       "      <td>85.680188</td>\n",
       "      <td>87.738073</td>\n",
       "      <td>136.487540</td>\n",
       "      <td>141.523761</td>\n",
       "      <td>101.131808</td>\n",
       "      <td>108.858054</td>\n",
       "      <td>-54.068323</td>\n",
       "      <td>65.626858</td>\n",
       "      <td>-14.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>140.659073</td>\n",
       "      <td>125.350209</td>\n",
       "      <td>129.599800</td>\n",
       "      <td>108.091486</td>\n",
       "      <td>119.659017</td>\n",
       "      <td>107.034203</td>\n",
       "      <td>104.168178</td>\n",
       "      <td>93.910614</td>\n",
       "      <td>124.524714</td>\n",
       "      <td>123.857795</td>\n",
       "      <td>...</td>\n",
       "      <td>105.910085</td>\n",
       "      <td>102.836555</td>\n",
       "      <td>102.774294</td>\n",
       "      <td>112.794817</td>\n",
       "      <td>103.911492</td>\n",
       "      <td>109.556471</td>\n",
       "      <td>86.656922</td>\n",
       "      <td>41.072800</td>\n",
       "      <td>30.039467</td>\n",
       "      <td>28.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>123.582703</td>\n",
       "      <td>137.822751</td>\n",
       "      <td>94.717003</td>\n",
       "      <td>105.845773</td>\n",
       "      <td>123.579445</td>\n",
       "      <td>153.444992</td>\n",
       "      <td>107.160292</td>\n",
       "      <td>117.265185</td>\n",
       "      <td>109.454176</td>\n",
       "      <td>132.509585</td>\n",
       "      <td>...</td>\n",
       "      <td>129.847759</td>\n",
       "      <td>68.217700</td>\n",
       "      <td>99.064472</td>\n",
       "      <td>126.846429</td>\n",
       "      <td>136.461456</td>\n",
       "      <td>85.707251</td>\n",
       "      <td>101.464057</td>\n",
       "      <td>-23.672791</td>\n",
       "      <td>64.501573</td>\n",
       "      <td>-42.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>117.767122</td>\n",
       "      <td>131.730944</td>\n",
       "      <td>90.237444</td>\n",
       "      <td>109.108210</td>\n",
       "      <td>132.774084</td>\n",
       "      <td>137.241918</td>\n",
       "      <td>106.946625</td>\n",
       "      <td>121.461838</td>\n",
       "      <td>110.891099</td>\n",
       "      <td>124.672675</td>\n",
       "      <td>...</td>\n",
       "      <td>123.063992</td>\n",
       "      <td>77.499631</td>\n",
       "      <td>100.041223</td>\n",
       "      <td>109.083787</td>\n",
       "      <td>124.040097</td>\n",
       "      <td>92.860534</td>\n",
       "      <td>106.933579</td>\n",
       "      <td>-19.216421</td>\n",
       "      <td>37.863869</td>\n",
       "      <td>-32.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>144.703994</td>\n",
       "      <td>146.429798</td>\n",
       "      <td>129.153855</td>\n",
       "      <td>123.777318</td>\n",
       "      <td>116.176162</td>\n",
       "      <td>126.098591</td>\n",
       "      <td>94.806920</td>\n",
       "      <td>87.366211</td>\n",
       "      <td>144.996567</td>\n",
       "      <td>138.931276</td>\n",
       "      <td>...</td>\n",
       "      <td>135.813260</td>\n",
       "      <td>99.858661</td>\n",
       "      <td>104.897725</td>\n",
       "      <td>120.095453</td>\n",
       "      <td>114.794911</td>\n",
       "      <td>85.117999</td>\n",
       "      <td>88.509158</td>\n",
       "      <td>58.681855</td>\n",
       "      <td>58.155209</td>\n",
       "      <td>-0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "1141  118.426550  132.352497   89.567949   96.506083  136.600493  155.498352   \n",
       "2210  140.659073  125.350209  129.599800  108.091486  119.659017  107.034203   \n",
       "441   123.582703  137.822751   94.717003  105.845773  123.579445  153.444992   \n",
       "682   117.767122  131.730944   90.237444  109.108210  132.774084  137.241918   \n",
       "1479  144.703994  146.429798  129.153855  123.777318  116.176162  126.098591   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...    sensor42  \\\n",
       "1141  110.825086  124.818256  118.123353  121.818280  ...  124.104267   \n",
       "2210  104.168178   93.910614  124.524714  123.857795  ...  105.910085   \n",
       "441   107.160292  117.265185  109.454176  132.509585  ...  129.847759   \n",
       "682   106.946625  121.461838  110.891099  124.672675  ...  123.063992   \n",
       "1479   94.806920   87.366211  144.996567  138.931276  ...  135.813260   \n",
       "\n",
       "        sensor43    sensor44    sensor45    sensor46    sensor47    sensor48  \\\n",
       "1141   85.680188   87.738073  136.487540  141.523761  101.131808  108.858054   \n",
       "2210  102.836555  102.774294  112.794817  103.911492  109.556471   86.656922   \n",
       "441    68.217700   99.064472  126.846429  136.461456   85.707251  101.464057   \n",
       "682    77.499631  100.041223  109.083787  124.040097   92.860534  106.933579   \n",
       "1479   99.858661  104.897725  120.095453  114.794911   85.117999   88.509158   \n",
       "\n",
       "           PosX       PosY   PosZ  \n",
       "1141 -54.068323  65.626858 -14.36  \n",
       "2210  41.072800  30.039467  28.40  \n",
       "441  -23.672791  64.501573 -42.36  \n",
       "682  -19.216421  37.863869 -32.72  \n",
       "1479  58.681855  58.155209  -0.84  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11c9afc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of the Dataset is :  (2443, 51)\n",
      "************************************************************************************************************\n",
      "Column Names of the Dataset are :  Index(['sensor1', 'sensor2', 'sensor3', 'sensor4', 'sensor5', 'sensor6',\n",
      "       'sensor7', 'sensor8', 'sensor9', 'sensor10', 'sensor11', 'sensor12',\n",
      "       'sensor13', 'sensor14', 'sensor15', 'sensor16', 'sensor17', 'sensor18',\n",
      "       'sensor19', 'sensor20', 'sensor21', 'sensor22', 'sensor23', 'sensor24',\n",
      "       'sensor25', 'sensor26', 'sensor27', 'sensor28', 'sensor29', 'sensor30',\n",
      "       'sensor31', 'sensor32', 'sensor33', 'sensor34', 'sensor35', 'sensor36',\n",
      "       'sensor37', 'sensor38', 'sensor39', 'sensor40', 'sensor41', 'sensor42',\n",
      "       'sensor43', 'sensor44', 'sensor45', 'sensor46', 'sensor47', 'sensor48',\n",
      "       'PosX', 'PosY', 'PosZ'],\n",
      "      dtype='object')\n",
      "************************************************************************************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2443 entries, 0 to 2442\n",
      "Data columns (total 51 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   sensor1   2443 non-null   float64\n",
      " 1   sensor2   2443 non-null   float64\n",
      " 2   sensor3   2443 non-null   float64\n",
      " 3   sensor4   2443 non-null   float64\n",
      " 4   sensor5   2443 non-null   float64\n",
      " 5   sensor6   2443 non-null   float64\n",
      " 6   sensor7   2443 non-null   float64\n",
      " 7   sensor8   2443 non-null   float64\n",
      " 8   sensor9   2443 non-null   float64\n",
      " 9   sensor10  2443 non-null   float64\n",
      " 10  sensor11  2443 non-null   float64\n",
      " 11  sensor12  2443 non-null   float64\n",
      " 12  sensor13  2443 non-null   float64\n",
      " 13  sensor14  2443 non-null   float64\n",
      " 14  sensor15  2443 non-null   float64\n",
      " 15  sensor16  2443 non-null   float64\n",
      " 16  sensor17  2443 non-null   float64\n",
      " 17  sensor18  2443 non-null   float64\n",
      " 18  sensor19  2443 non-null   float64\n",
      " 19  sensor20  2443 non-null   float64\n",
      " 20  sensor21  2443 non-null   float64\n",
      " 21  sensor22  2443 non-null   float64\n",
      " 22  sensor23  2443 non-null   float64\n",
      " 23  sensor24  2443 non-null   float64\n",
      " 24  sensor25  2443 non-null   float64\n",
      " 25  sensor26  2443 non-null   float64\n",
      " 26  sensor27  2443 non-null   float64\n",
      " 27  sensor28  2443 non-null   float64\n",
      " 28  sensor29  2443 non-null   float64\n",
      " 29  sensor30  2443 non-null   float64\n",
      " 30  sensor31  2443 non-null   float64\n",
      " 31  sensor32  2443 non-null   float64\n",
      " 32  sensor33  2443 non-null   float64\n",
      " 33  sensor34  2443 non-null   float64\n",
      " 34  sensor35  2443 non-null   float64\n",
      " 35  sensor36  2443 non-null   float64\n",
      " 36  sensor37  2443 non-null   float64\n",
      " 37  sensor38  2443 non-null   float64\n",
      " 38  sensor39  2443 non-null   float64\n",
      " 39  sensor40  2443 non-null   float64\n",
      " 40  sensor41  2443 non-null   float64\n",
      " 41  sensor42  2443 non-null   float64\n",
      " 42  sensor43  2443 non-null   float64\n",
      " 43  sensor44  2443 non-null   float64\n",
      " 44  sensor45  2443 non-null   float64\n",
      " 45  sensor46  2443 non-null   float64\n",
      " 46  sensor47  2443 non-null   float64\n",
      " 47  sensor48  2443 non-null   float64\n",
      " 48  PosX      2443 non-null   float64\n",
      " 49  PosY      2443 non-null   float64\n",
      " 50  PosZ      2443 non-null   float64\n",
      "dtypes: float64(51)\n",
      "memory usage: 973.5 KB\n",
      "None\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "      <th>PosX</th>\n",
       "      <th>PosY</th>\n",
       "      <th>PosZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>129.520130</td>\n",
       "      <td>133.780501</td>\n",
       "      <td>104.462099</td>\n",
       "      <td>110.450076</td>\n",
       "      <td>128.595627</td>\n",
       "      <td>133.391181</td>\n",
       "      <td>103.272045</td>\n",
       "      <td>109.726055</td>\n",
       "      <td>124.701813</td>\n",
       "      <td>128.010306</td>\n",
       "      <td>...</td>\n",
       "      <td>125.263258</td>\n",
       "      <td>91.123794</td>\n",
       "      <td>98.591957</td>\n",
       "      <td>119.624760</td>\n",
       "      <td>124.936219</td>\n",
       "      <td>90.600711</td>\n",
       "      <td>98.341490</td>\n",
       "      <td>1.587217</td>\n",
       "      <td>50.342157</td>\n",
       "      <td>-11.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.182080</td>\n",
       "      <td>12.330503</td>\n",
       "      <td>14.952531</td>\n",
       "      <td>15.769194</td>\n",
       "      <td>12.737396</td>\n",
       "      <td>12.043886</td>\n",
       "      <td>15.862698</td>\n",
       "      <td>14.681821</td>\n",
       "      <td>11.901381</td>\n",
       "      <td>12.007304</td>\n",
       "      <td>...</td>\n",
       "      <td>10.139607</td>\n",
       "      <td>12.102077</td>\n",
       "      <td>13.068165</td>\n",
       "      <td>10.116794</td>\n",
       "      <td>10.060208</td>\n",
       "      <td>13.049884</td>\n",
       "      <td>12.415964</td>\n",
       "      <td>41.974722</td>\n",
       "      <td>14.164250</td>\n",
       "      <td>28.215107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>91.665371</td>\n",
       "      <td>99.171297</td>\n",
       "      <td>64.891828</td>\n",
       "      <td>66.368265</td>\n",
       "      <td>93.169908</td>\n",
       "      <td>99.137912</td>\n",
       "      <td>57.953785</td>\n",
       "      <td>70.062967</td>\n",
       "      <td>87.817782</td>\n",
       "      <td>93.152801</td>\n",
       "      <td>...</td>\n",
       "      <td>92.464922</td>\n",
       "      <td>52.768022</td>\n",
       "      <td>58.341795</td>\n",
       "      <td>91.353260</td>\n",
       "      <td>94.756293</td>\n",
       "      <td>53.592624</td>\n",
       "      <td>63.470231</td>\n",
       "      <td>-59.999924</td>\n",
       "      <td>30.000015</td>\n",
       "      <td>-60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>120.914118</td>\n",
       "      <td>124.723676</td>\n",
       "      <td>93.258509</td>\n",
       "      <td>99.107826</td>\n",
       "      <td>119.372028</td>\n",
       "      <td>125.146667</td>\n",
       "      <td>91.246071</td>\n",
       "      <td>99.232216</td>\n",
       "      <td>116.447017</td>\n",
       "      <td>119.564911</td>\n",
       "      <td>...</td>\n",
       "      <td>117.702666</td>\n",
       "      <td>82.072080</td>\n",
       "      <td>89.513329</td>\n",
       "      <td>112.657323</td>\n",
       "      <td>118.103115</td>\n",
       "      <td>81.275663</td>\n",
       "      <td>88.904424</td>\n",
       "      <td>-39.527147</td>\n",
       "      <td>36.118033</td>\n",
       "      <td>-35.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>130.112275</td>\n",
       "      <td>133.261726</td>\n",
       "      <td>104.599125</td>\n",
       "      <td>111.491363</td>\n",
       "      <td>127.779291</td>\n",
       "      <td>133.826057</td>\n",
       "      <td>103.869465</td>\n",
       "      <td>111.045237</td>\n",
       "      <td>124.854551</td>\n",
       "      <td>127.507417</td>\n",
       "      <td>...</td>\n",
       "      <td>125.060542</td>\n",
       "      <td>91.603602</td>\n",
       "      <td>99.211583</td>\n",
       "      <td>119.438926</td>\n",
       "      <td>125.384501</td>\n",
       "      <td>91.469233</td>\n",
       "      <td>98.758381</td>\n",
       "      <td>2.638047</td>\n",
       "      <td>50.895260</td>\n",
       "      <td>-11.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>138.529701</td>\n",
       "      <td>143.105289</td>\n",
       "      <td>116.275822</td>\n",
       "      <td>122.201802</td>\n",
       "      <td>137.560467</td>\n",
       "      <td>142.507457</td>\n",
       "      <td>115.286522</td>\n",
       "      <td>120.578263</td>\n",
       "      <td>133.712263</td>\n",
       "      <td>137.057920</td>\n",
       "      <td>...</td>\n",
       "      <td>132.427154</td>\n",
       "      <td>99.913608</td>\n",
       "      <td>108.253040</td>\n",
       "      <td>126.331698</td>\n",
       "      <td>132.368420</td>\n",
       "      <td>100.211181</td>\n",
       "      <td>108.069122</td>\n",
       "      <td>43.349064</td>\n",
       "      <td>64.452757</td>\n",
       "      <td>13.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>160.413412</td>\n",
       "      <td>170.924619</td>\n",
       "      <td>143.914782</td>\n",
       "      <td>150.959576</td>\n",
       "      <td>162.059422</td>\n",
       "      <td>165.695254</td>\n",
       "      <td>145.462122</td>\n",
       "      <td>146.995244</td>\n",
       "      <td>155.844108</td>\n",
       "      <td>162.528384</td>\n",
       "      <td>...</td>\n",
       "      <td>153.214361</td>\n",
       "      <td>127.840963</td>\n",
       "      <td>133.436651</td>\n",
       "      <td>150.951445</td>\n",
       "      <td>154.995619</td>\n",
       "      <td>124.404066</td>\n",
       "      <td>135.464393</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>69.999999</td>\n",
       "      <td>37.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sensor1      sensor2      sensor3      sensor4      sensor5  \\\n",
       "count  2443.000000  2443.000000  2443.000000  2443.000000  2443.000000   \n",
       "mean    129.520130   133.780501   104.462099   110.450076   128.595627   \n",
       "std      12.182080    12.330503    14.952531    15.769194    12.737396   \n",
       "min      91.665371    99.171297    64.891828    66.368265    93.169908   \n",
       "25%     120.914118   124.723676    93.258509    99.107826   119.372028   \n",
       "50%     130.112275   133.261726   104.599125   111.491363   127.779291   \n",
       "75%     138.529701   143.105289   116.275822   122.201802   137.560467   \n",
       "max     160.413412   170.924619   143.914782   150.959576   162.059422   \n",
       "\n",
       "           sensor6      sensor7      sensor8      sensor9     sensor10  ...  \\\n",
       "count  2443.000000  2443.000000  2443.000000  2443.000000  2443.000000  ...   \n",
       "mean    133.391181   103.272045   109.726055   124.701813   128.010306  ...   \n",
       "std      12.043886    15.862698    14.681821    11.901381    12.007304  ...   \n",
       "min      99.137912    57.953785    70.062967    87.817782    93.152801  ...   \n",
       "25%     125.146667    91.246071    99.232216   116.447017   119.564911  ...   \n",
       "50%     133.826057   103.869465   111.045237   124.854551   127.507417  ...   \n",
       "75%     142.507457   115.286522   120.578263   133.712263   137.057920  ...   \n",
       "max     165.695254   145.462122   146.995244   155.844108   162.528384  ...   \n",
       "\n",
       "          sensor42     sensor43     sensor44     sensor45     sensor46  \\\n",
       "count  2443.000000  2443.000000  2443.000000  2443.000000  2443.000000   \n",
       "mean    125.263258    91.123794    98.591957   119.624760   124.936219   \n",
       "std      10.139607    12.102077    13.068165    10.116794    10.060208   \n",
       "min      92.464922    52.768022    58.341795    91.353260    94.756293   \n",
       "25%     117.702666    82.072080    89.513329   112.657323   118.103115   \n",
       "50%     125.060542    91.603602    99.211583   119.438926   125.384501   \n",
       "75%     132.427154    99.913608   108.253040   126.331698   132.368420   \n",
       "max     153.214361   127.840963   133.436651   150.951445   154.995619   \n",
       "\n",
       "          sensor47     sensor48         PosX         PosY         PosZ  \n",
       "count  2443.000000  2443.000000  2443.000000  2443.000000  2443.000000  \n",
       "mean     90.600711    98.341490     1.587217    50.342157   -11.160000  \n",
       "std      13.049884    12.415964    41.974722    14.164250    28.215107  \n",
       "min      53.592624    63.470231   -59.999924    30.000015   -60.000000  \n",
       "25%      81.275663    88.904424   -39.527147    36.118033   -35.580000  \n",
       "50%      91.469233    98.758381     2.638047    50.895260   -11.160000  \n",
       "75%     100.211181   108.069122    43.349064    64.452757    13.260000  \n",
       "max     124.404066   135.464393    60.000000    69.999999    37.680000  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The Shape of the Dataset is : \",raw_data.shape)\n",
    "print(\"************************************************************************************************************\")\n",
    "print(\"Column Names of the Dataset are : \",raw_data.columns)\n",
    "print(\"************************************************************************************************************\")\n",
    "print(raw_data.info())\n",
    "print(\"************************************************************************************************************\")\n",
    "raw_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e4aca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor1     False\n",
      "sensor2     False\n",
      "sensor3     False\n",
      "sensor4     False\n",
      "sensor5     False\n",
      "sensor6     False\n",
      "sensor7     False\n",
      "sensor8     False\n",
      "sensor9     False\n",
      "sensor10    False\n",
      "sensor11    False\n",
      "sensor12    False\n",
      "sensor13    False\n",
      "sensor14    False\n",
      "sensor15    False\n",
      "sensor16    False\n",
      "sensor17    False\n",
      "sensor18    False\n",
      "sensor19    False\n",
      "sensor20    False\n",
      "sensor21    False\n",
      "sensor22    False\n",
      "sensor23    False\n",
      "sensor24    False\n",
      "sensor25    False\n",
      "sensor26    False\n",
      "sensor27    False\n",
      "sensor28    False\n",
      "sensor29    False\n",
      "sensor30    False\n",
      "sensor31    False\n",
      "sensor32    False\n",
      "sensor33    False\n",
      "sensor34    False\n",
      "sensor35    False\n",
      "sensor36    False\n",
      "sensor37    False\n",
      "sensor38    False\n",
      "sensor39    False\n",
      "sensor40    False\n",
      "sensor41    False\n",
      "sensor42    False\n",
      "sensor43    False\n",
      "sensor44    False\n",
      "sensor45    False\n",
      "sensor46    False\n",
      "sensor47    False\n",
      "sensor48    False\n",
      "PosX        False\n",
      "PosY        False\n",
      "PosZ        False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2099cfda",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/mahmoudftolba/a-detailed-regression-eda-for-beginners\n",
    "    \n",
    "https://www.kaggle.com/datasets/birdy654/eeg-brainwave-dataset-feeling-emotions/code?datasetId=93959&sortBy=voteCount\n",
    "    \n",
    "https://www.kaggle.com/code/mustafaashraf/emotions-svm-roc\n",
    "    \n",
    "https://www.kaggle.com/code/fathihilmi/final-year-project-gru\n",
    "    \n",
    "https://www.kaggle.com/code/ssunssai/prediction-emotion-from-eeg-signal\n",
    "    \n",
    "https://www.kaggle.com/code/shreyaspj/detecting-emotions-using-eeg-waves\n",
    "    \n",
    "https://www.kaggle.com/code/gcdatkin/eeg-emotion-prediction\n",
    "    \n",
    "https://www.kaggle.com/code/thebrownviking20/intro-to-recurrent-neural-networks-lstm-gru\n",
    "\n",
    "https://www.kaggle.com/code/sohommajumder21/medical-cost-8-models-90-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0799c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "y =position_data\n",
    "x_train, x_test, y_train, y_test = train_test_split( sensors_data , y , test_size=0.2 , random_state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03286677",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/datark1/customers-clustering-k-means-dbscan-and-ap\n",
    "\n",
    "https://www.kaggle.com/code/aayush7kumar/clustering-using-k-means-hierarchical-and-dbscan\n",
    "\n",
    "https://www.kaggle.com/code/niteshyadav3103/customer-segmentation-using-kmeans-hc-dbscan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c38ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442dcb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b190458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22637780",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/shreyaspj/confused-student-eeg-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df51a722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1954, 48), (489, 48), (1954, 3), (489, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "618906f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).reshape(-1,48,1)\n",
    "x_test = np.array(x_test).reshape(-1,48,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35719d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1954, 48, 1), (489, 48, 1), (1954, 3), (489, 3))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e8ccfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "#from pywt import wavedec\n",
    "from functools import reduce\n",
    "from scipy import signal\n",
    "from scipy.stats import entropy\n",
    "from scipy.fft import fft, ifft\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold,cross_validate\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, concatenate, Input, Dropout, LSTM, Bidirectional,BatchNormalization,PReLU,ReLU,Reshape\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "import matplotlib.pyplot as plt;\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D,Add\n",
    "from tensorflow.keras.layers import MaxPool1D, MaxPooling2D\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4d5221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 48, 1)]           0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 48, 64)            128       \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 48, 512)          657408    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 48, 512)           0         \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 48, 256)          656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 48, 256)           0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12288)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               1572992   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,887,299\n",
      "Trainable params: 2,887,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(48,1))\n",
    "\n",
    "Dense1 = Dense(64, activation = 'relu',kernel_regularizer=keras.regularizers.l2())(inputs)\n",
    "\n",
    "#Dense2 = Dense(128, activation = 'relu',kernel_regularizer=keras.regularizers.l2())(Dense1)\n",
    "#Dense3 = Dense(256, activation = 'relu',kernel_regularizer=keras.regularizers.l2())(Dense2)\n",
    "\n",
    "lstm_1=  Bidirectional(LSTM(256, return_sequences = True))(Dense1)\n",
    "drop = Dropout(0.3)(lstm_1)\n",
    "lstm_3=  Bidirectional(LSTM(128, return_sequences = True))(drop)\n",
    "drop2 = Dropout(0.3)(lstm_3)\n",
    "\n",
    "flat = Flatten()(drop2)\n",
    "\n",
    "#Dense_1 = Dense(256, activation = 'relu')(flat)\n",
    "\n",
    "Dense_2 = Dense(128, activation = 'relu')(flat)\n",
    "outputs = Dense(3, activation='sigmoid')(Dense_2)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc0f2307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d848ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,x_train, y_train,x_test,y_test, save_to, epoch = 2):\n",
    "\n",
    "        opt_adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "        mc = ModelCheckpoint(save_to + '_best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "        lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
    "        \n",
    "        model.compile(optimizer=opt_adam,\n",
    "                  loss=['binary_crossentropy'],\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "        history = model.fit(x_train,y_train,\n",
    "                        batch_size=20,\n",
    "                        epochs=epoch,\n",
    "                        validation_data=(x_test,y_test),\n",
    "                        callbacks=[es,mc,lr_schedule])\n",
    "        \n",
    "        saved_model = load_model(save_to + '_best_model.h5')\n",
    "        \n",
    "        return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4de1637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -117567.6484 - accuracy: 0.7815\n",
      "Epoch 1: val_accuracy improved from -inf to 0.83027, saving model to .\\_best_model.h5\n",
      "98/98 [==============================] - 17s 48ms/step - loss: -117567.6484 - accuracy: 0.7815 - val_loss: -329247.8438 - val_accuracy: 0.8303 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -686614.7500 - accuracy: 0.7902\n",
      "Epoch 2: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -690326.7500 - accuracy: 0.7907 - val_loss: -1139822.1250 - val_accuracy: 0.8303 - lr: 9.0484e-04\n",
      "Epoch 3/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -1696367.3750 - accuracy: 0.7918\n",
      "Epoch 3: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -1698947.3750 - accuracy: 0.7907 - val_loss: -2312250.2500 - val_accuracy: 0.8303 - lr: 8.1873e-04\n",
      "Epoch 4/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -2995313.7500 - accuracy: 0.7918\n",
      "Epoch 4: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -3006549.2500 - accuracy: 0.7907 - val_loss: -3705853.5000 - val_accuracy: 0.8303 - lr: 7.4082e-04\n",
      "Epoch 5/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -4486584.0000 - accuracy: 0.7912\n",
      "Epoch 5: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -4488549.5000 - accuracy: 0.7907 - val_loss: -5227224.0000 - val_accuracy: 0.8303 - lr: 6.7032e-04\n",
      "Epoch 6/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -6058362.0000 - accuracy: 0.7918\n",
      "Epoch 6: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -6056106.0000 - accuracy: 0.7907 - val_loss: -6788071.5000 - val_accuracy: 0.8303 - lr: 6.0653e-04\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -7638992.0000 - accuracy: 0.7907\n",
      "Epoch 7: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -7638992.0000 - accuracy: 0.7907 - val_loss: -8343831.5000 - val_accuracy: 0.8303 - lr: 5.4881e-04\n",
      "Epoch 8/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -9205626.0000 - accuracy: 0.7892\n",
      "Epoch 8: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -9211216.0000 - accuracy: 0.7907 - val_loss: -9865773.0000 - val_accuracy: 0.8303 - lr: 4.9659e-04\n",
      "Epoch 9/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -10703891.0000 - accuracy: 0.7902\n",
      "Epoch 9: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -10726517.0000 - accuracy: 0.7907 - val_loss: -11323919.0000 - val_accuracy: 0.8303 - lr: 4.4933e-04\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -12169279.0000 - accuracy: 0.7907\n",
      "Epoch 10: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -12169279.0000 - accuracy: 0.7907 - val_loss: -12706385.0000 - val_accuracy: 0.8303 - lr: 4.0657e-04\n",
      "Epoch 11/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -13532404.0000 - accuracy: 0.7902\n",
      "Epoch 11: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -13526412.0000 - accuracy: 0.7907 - val_loss: -13994745.0000 - val_accuracy: 0.8303 - lr: 3.6788e-04\n",
      "Epoch 12/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -14810498.0000 - accuracy: 0.7918\n",
      "Epoch 12: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -14790326.0000 - accuracy: 0.7907 - val_loss: -15194571.0000 - val_accuracy: 0.8303 - lr: 3.3287e-04\n",
      "Epoch 13/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -15996227.0000 - accuracy: 0.7912\n",
      "Epoch 13: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -15963957.0000 - accuracy: 0.7907 - val_loss: -16302442.0000 - val_accuracy: 0.8303 - lr: 3.0119e-04\n",
      "Epoch 14/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -17050490.0000 - accuracy: 0.7918\n",
      "Epoch 14: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -17049538.0000 - accuracy: 0.7907 - val_loss: -17322150.0000 - val_accuracy: 0.8303 - lr: 2.7253e-04\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -18045866.0000 - accuracy: 0.7907\n",
      "Epoch 15: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -18045866.0000 - accuracy: 0.7907 - val_loss: -18260270.0000 - val_accuracy: 0.8303 - lr: 2.4660e-04\n",
      "Epoch 16/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -18956046.0000 - accuracy: 0.7912\n",
      "Epoch 16: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -18956624.0000 - accuracy: 0.7907 - val_loss: -19114664.0000 - val_accuracy: 0.8303 - lr: 2.2313e-04\n",
      "Epoch 17/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -19786340.0000 - accuracy: 0.7892\n",
      "Epoch 17: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -19784938.0000 - accuracy: 0.7907 - val_loss: -19890916.0000 - val_accuracy: 0.8303 - lr: 2.0190e-04\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -20548506.0000 - accuracy: 0.7907\n",
      "Epoch 18: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -20548506.0000 - accuracy: 0.7907 - val_loss: -20604548.0000 - val_accuracy: 0.8303 - lr: 1.8268e-04\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -21234200.0000 - accuracy: 0.7907\n",
      "Epoch 19: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -21234200.0000 - accuracy: 0.7907 - val_loss: -21246446.0000 - val_accuracy: 0.8303 - lr: 1.6530e-04\n",
      "Epoch 20/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -21850080.0000 - accuracy: 0.7923\n",
      "Epoch 20: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -21865618.0000 - accuracy: 0.7907 - val_loss: -21834482.0000 - val_accuracy: 0.8303 - lr: 1.4957e-04\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -22433252.0000 - accuracy: 0.7907\n",
      "Epoch 21: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -22433252.0000 - accuracy: 0.7907 - val_loss: -22363734.0000 - val_accuracy: 0.8303 - lr: 1.3534e-04\n",
      "Epoch 22/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -22960760.0000 - accuracy: 0.7918\n",
      "Epoch 22: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -22939192.0000 - accuracy: 0.7907 - val_loss: -22844104.0000 - val_accuracy: 0.8303 - lr: 1.2246e-04\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -23412096.0000 - accuracy: 0.7907\n",
      "Epoch 23: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -23412096.0000 - accuracy: 0.7907 - val_loss: -23277980.0000 - val_accuracy: 0.8303 - lr: 1.1080e-04\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -23827388.0000 - accuracy: 0.7907\n",
      "Epoch 24: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -23827388.0000 - accuracy: 0.7907 - val_loss: -23670884.0000 - val_accuracy: 0.8303 - lr: 1.0026e-04\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -24209770.0000 - accuracy: 0.7907\n",
      "Epoch 25: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -24209770.0000 - accuracy: 0.7907 - val_loss: -24026168.0000 - val_accuracy: 0.8303 - lr: 9.0718e-05\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -24549114.0000 - accuracy: 0.7907\n",
      "Epoch 26: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -24549114.0000 - accuracy: 0.7907 - val_loss: -24346170.0000 - val_accuracy: 0.8303 - lr: 8.2085e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -24860888.0000 - accuracy: 0.7907\n",
      "Epoch 27: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -24860888.0000 - accuracy: 0.7907 - val_loss: -24633776.0000 - val_accuracy: 0.8303 - lr: 7.4274e-05\n",
      "Epoch 28/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -25107100.0000 - accuracy: 0.7902\n",
      "Epoch 28: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -25142596.0000 - accuracy: 0.7907 - val_loss: -24897060.0000 - val_accuracy: 0.8303 - lr: 6.7206e-05\n",
      "Epoch 29/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -25395478.0000 - accuracy: 0.7902\n",
      "Epoch 29: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -25398146.0000 - accuracy: 0.7907 - val_loss: -25133210.0000 - val_accuracy: 0.8303 - lr: 6.0810e-05\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -25626976.0000 - accuracy: 0.7907\n",
      "Epoch 30: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -25626976.0000 - accuracy: 0.7907 - val_loss: -25350110.0000 - val_accuracy: 0.8303 - lr: 5.5023e-05\n",
      "Epoch 31/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -25848646.0000 - accuracy: 0.7897\n",
      "Epoch 31: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -25829996.0000 - accuracy: 0.7907 - val_loss: -25542058.0000 - val_accuracy: 0.8303 - lr: 4.9787e-05\n",
      "Epoch 32/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -26034938.0000 - accuracy: 0.7897\n",
      "Epoch 32: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -26023908.0000 - accuracy: 0.7907 - val_loss: -25715496.0000 - val_accuracy: 0.8303 - lr: 4.5049e-05\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -26188638.0000 - accuracy: 0.7907\n",
      "Epoch 33: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -26188638.0000 - accuracy: 0.7907 - val_loss: -25872494.0000 - val_accuracy: 0.8303 - lr: 4.0762e-05\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -26335266.0000 - accuracy: 0.7907\n",
      "Epoch 34: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -26335266.0000 - accuracy: 0.7907 - val_loss: -26013886.0000 - val_accuracy: 0.8303 - lr: 3.6883e-05\n",
      "Epoch 35/100\n",
      "95/98 [============================>.] - ETA: 0s - loss: -26372942.0000 - accuracy: 0.7905\n",
      "Epoch 35: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -26474190.0000 - accuracy: 0.7907 - val_loss: -26142090.0000 - val_accuracy: 0.8303 - lr: 3.3373e-05\n",
      "Epoch 36/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -26594676.0000 - accuracy: 0.7912\n",
      "Epoch 36: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -26605892.0000 - accuracy: 0.7907 - val_loss: -26256886.0000 - val_accuracy: 0.8303 - lr: 3.0197e-05\n",
      "Epoch 37/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -26757288.0000 - accuracy: 0.7902\n",
      "Epoch 37: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -26718106.0000 - accuracy: 0.7907 - val_loss: -26361964.0000 - val_accuracy: 0.8303 - lr: 2.7324e-05\n",
      "Epoch 38/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -26852490.0000 - accuracy: 0.7923\n",
      "Epoch 38: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -26808310.0000 - accuracy: 0.7907 - val_loss: -26457504.0000 - val_accuracy: 0.8303 - lr: 2.4724e-05\n",
      "Epoch 39/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: -26862532.0000 - accuracy: 0.7906\n",
      "Epoch 39: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -26902860.0000 - accuracy: 0.7907 - val_loss: -26541988.0000 - val_accuracy: 0.8303 - lr: 2.2371e-05\n",
      "Epoch 40/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27011902.0000 - accuracy: 0.7902\n",
      "Epoch 40: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -26997046.0000 - accuracy: 0.7907 - val_loss: -26617426.0000 - val_accuracy: 0.8303 - lr: 2.0242e-05\n",
      "Epoch 41/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: -27115478.0000 - accuracy: 0.7922\n",
      "Epoch 41: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27058494.0000 - accuracy: 0.7907 - val_loss: -26687348.0000 - val_accuracy: 0.8303 - lr: 1.8316e-05\n",
      "Epoch 42/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27110862.0000 - accuracy: 0.7902\n",
      "Epoch 42: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27127336.0000 - accuracy: 0.7907 - val_loss: -26750002.0000 - val_accuracy: 0.8303 - lr: 1.6573e-05\n",
      "Epoch 43/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27178826.0000 - accuracy: 0.7902\n",
      "Epoch 43: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27188044.0000 - accuracy: 0.7907 - val_loss: -26805478.0000 - val_accuracy: 0.8303 - lr: 1.4996e-05\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27248016.0000 - accuracy: 0.7907\n",
      "Epoch 44: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -27248016.0000 - accuracy: 0.7907 - val_loss: -26858194.0000 - val_accuracy: 0.8303 - lr: 1.3569e-05\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27292524.0000 - accuracy: 0.7907\n",
      "Epoch 45: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -27292524.0000 - accuracy: 0.7907 - val_loss: -26904516.0000 - val_accuracy: 0.8303 - lr: 1.2277e-05\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27336702.0000 - accuracy: 0.7907\n",
      "Epoch 46: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -27336702.0000 - accuracy: 0.7907 - val_loss: -26945854.0000 - val_accuracy: 0.8303 - lr: 1.1109e-05\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27377980.0000 - accuracy: 0.7907\n",
      "Epoch 47: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27377980.0000 - accuracy: 0.7907 - val_loss: -26983196.0000 - val_accuracy: 0.8303 - lr: 1.0052e-05\n",
      "Epoch 48/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27444538.0000 - accuracy: 0.7907\n",
      "Epoch 48: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27410848.0000 - accuracy: 0.7907 - val_loss: -27017358.0000 - val_accuracy: 0.8303 - lr: 9.0953e-06\n",
      "Epoch 49/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27438742.0000 - accuracy: 0.7902\n",
      "Epoch 49: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27444368.0000 - accuracy: 0.7907 - val_loss: -27048816.0000 - val_accuracy: 0.8303 - lr: 8.2297e-06\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27478870.0000 - accuracy: 0.7907\n",
      "Epoch 50: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27478870.0000 - accuracy: 0.7907 - val_loss: -27077136.0000 - val_accuracy: 0.8303 - lr: 7.4466e-06\n",
      "Epoch 51/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27517692.0000 - accuracy: 0.7907\n",
      "Epoch 51: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27503816.0000 - accuracy: 0.7907 - val_loss: -27102518.0000 - val_accuracy: 0.8303 - lr: 6.7379e-06\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27523572.0000 - accuracy: 0.7907\n",
      "Epoch 52: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -27523572.0000 - accuracy: 0.7907 - val_loss: -27124976.0000 - val_accuracy: 0.8303 - lr: 6.0967e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27544770.0000 - accuracy: 0.7912\n",
      "Epoch 53: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27552184.0000 - accuracy: 0.7907 - val_loss: -27146288.0000 - val_accuracy: 0.8303 - lr: 5.5166e-06\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27569828.0000 - accuracy: 0.7907\n",
      "Epoch 54: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27569828.0000 - accuracy: 0.7907 - val_loss: -27163548.0000 - val_accuracy: 0.8303 - lr: 4.9916e-06\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27587300.0000 - accuracy: 0.7907\n",
      "Epoch 55: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27587300.0000 - accuracy: 0.7907 - val_loss: -27181824.0000 - val_accuracy: 0.8303 - lr: 4.5166e-06\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27605970.0000 - accuracy: 0.7907\n",
      "Epoch 56: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -27605970.0000 - accuracy: 0.7907 - val_loss: -27196384.0000 - val_accuracy: 0.8303 - lr: 4.0868e-06\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27617828.0000 - accuracy: 0.7907\n",
      "Epoch 57: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27617828.0000 - accuracy: 0.7907 - val_loss: -27209660.0000 - val_accuracy: 0.8303 - lr: 3.6979e-06\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27637686.0000 - accuracy: 0.7907\n",
      "Epoch 58: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27637686.0000 - accuracy: 0.7907 - val_loss: -27222830.0000 - val_accuracy: 0.8303 - lr: 3.3460e-06\n",
      "Epoch 59/100\n",
      "96/98 [============================>.] - ETA: 0s - loss: -27645844.0000 - accuracy: 0.7906\n",
      "Epoch 59: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27642062.0000 - accuracy: 0.7907 - val_loss: -27232672.0000 - val_accuracy: 0.8303 - lr: 3.0276e-06\n",
      "Epoch 60/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27629316.0000 - accuracy: 0.7897\n",
      "Epoch 60: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27657166.0000 - accuracy: 0.7907 - val_loss: -27243874.0000 - val_accuracy: 0.8303 - lr: 2.7394e-06\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27662956.0000 - accuracy: 0.7907\n",
      "Epoch 61: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27662956.0000 - accuracy: 0.7907 - val_loss: -27253720.0000 - val_accuracy: 0.8303 - lr: 2.4788e-06\n",
      "Epoch 62/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27662656.0000 - accuracy: 0.7907\n",
      "Epoch 62: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27674652.0000 - accuracy: 0.7907 - val_loss: -27260826.0000 - val_accuracy: 0.8303 - lr: 2.2429e-06\n",
      "Epoch 63/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27662630.0000 - accuracy: 0.7902\n",
      "Epoch 63: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -27683178.0000 - accuracy: 0.7907 - val_loss: -27269154.0000 - val_accuracy: 0.8303 - lr: 2.0294e-06\n",
      "Epoch 64/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27676476.0000 - accuracy: 0.7897\n",
      "Epoch 64: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27684522.0000 - accuracy: 0.7907 - val_loss: -27275428.0000 - val_accuracy: 0.8303 - lr: 1.8363e-06\n",
      "Epoch 65/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27714594.0000 - accuracy: 0.7907\n",
      "Epoch 65: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27694488.0000 - accuracy: 0.7907 - val_loss: -27281138.0000 - val_accuracy: 0.8303 - lr: 1.6616e-06\n",
      "Epoch 66/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27696928.0000 - accuracy: 0.7897\n",
      "Epoch 66: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27704088.0000 - accuracy: 0.7907 - val_loss: -27288894.0000 - val_accuracy: 0.8303 - lr: 1.5034e-06\n",
      "Epoch 67/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27701350.0000 - accuracy: 0.7902\n",
      "Epoch 67: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27705562.0000 - accuracy: 0.7907 - val_loss: -27293756.0000 - val_accuracy: 0.8303 - lr: 1.3604e-06\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27713990.0000 - accuracy: 0.7907\n",
      "Epoch 68: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27713990.0000 - accuracy: 0.7907 - val_loss: -27296164.0000 - val_accuracy: 0.8303 - lr: 1.2309e-06\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27719954.0000 - accuracy: 0.7907\n",
      "Epoch 69: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27719954.0000 - accuracy: 0.7907 - val_loss: -27301098.0000 - val_accuracy: 0.8303 - lr: 1.1138e-06\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27723560.0000 - accuracy: 0.7907\n",
      "Epoch 70: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -27723560.0000 - accuracy: 0.7907 - val_loss: -27304408.0000 - val_accuracy: 0.8303 - lr: 1.0078e-06\n",
      "Epoch 71/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27707626.0000 - accuracy: 0.7912\n",
      "Epoch 71: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27715414.0000 - accuracy: 0.7907 - val_loss: -27307902.0000 - val_accuracy: 0.8303 - lr: 9.1188e-07\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27725682.0000 - accuracy: 0.7907\n",
      "Epoch 72: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27725682.0000 - accuracy: 0.7907 - val_loss: -27310194.0000 - val_accuracy: 0.8303 - lr: 8.2510e-07\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27729384.0000 - accuracy: 0.7907\n",
      "Epoch 73: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -27729384.0000 - accuracy: 0.7907 - val_loss: -27313440.0000 - val_accuracy: 0.8303 - lr: 7.4659e-07\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27725742.0000 - accuracy: 0.7907\n",
      "Epoch 74: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27725742.0000 - accuracy: 0.7907 - val_loss: -27316270.0000 - val_accuracy: 0.8303 - lr: 6.7554e-07\n",
      "Epoch 75/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27728338.0000 - accuracy: 0.7918\n",
      "Epoch 75: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27738552.0000 - accuracy: 0.7907 - val_loss: -27318682.0000 - val_accuracy: 0.8303 - lr: 6.1125e-07\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27739150.0000 - accuracy: 0.7907\n",
      "Epoch 76: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27739150.0000 - accuracy: 0.7907 - val_loss: -27321020.0000 - val_accuracy: 0.8303 - lr: 5.5308e-07\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27741806.0000 - accuracy: 0.7907\n",
      "Epoch 77: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -27741806.0000 - accuracy: 0.7907 - val_loss: -27323554.0000 - val_accuracy: 0.8303 - lr: 5.0045e-07\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27741138.0000 - accuracy: 0.7907\n",
      "Epoch 78: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27741138.0000 - accuracy: 0.7907 - val_loss: -27325968.0000 - val_accuracy: 0.8303 - lr: 4.5283e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27730892.0000 - accuracy: 0.7902\n",
      "Epoch 79: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27748060.0000 - accuracy: 0.7907 - val_loss: -27327226.0000 - val_accuracy: 0.8303 - lr: 4.0973e-07\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27745242.0000 - accuracy: 0.7907\n",
      "Epoch 80: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27745242.0000 - accuracy: 0.7907 - val_loss: -27327968.0000 - val_accuracy: 0.8303 - lr: 3.7074e-07\n",
      "Epoch 81/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27688226.0000 - accuracy: 0.7902\n",
      "Epoch 81: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27739492.0000 - accuracy: 0.7907 - val_loss: -27330518.0000 - val_accuracy: 0.8303 - lr: 3.3546e-07\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27746524.0000 - accuracy: 0.7907\n",
      "Epoch 82: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27746524.0000 - accuracy: 0.7907 - val_loss: -27330524.0000 - val_accuracy: 0.8303 - lr: 3.0354e-07\n",
      "Epoch 83/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27797090.0000 - accuracy: 0.7907\n",
      "Epoch 83: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 28ms/step - loss: -27754112.0000 - accuracy: 0.7907 - val_loss: -27330788.0000 - val_accuracy: 0.8303 - lr: 2.7465e-07\n",
      "Epoch 84/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27763032.0000 - accuracy: 0.7918\n",
      "Epoch 84: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27748610.0000 - accuracy: 0.7907 - val_loss: -27331286.0000 - val_accuracy: 0.8303 - lr: 2.4852e-07\n",
      "Epoch 85/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27743922.0000 - accuracy: 0.7907\n",
      "Epoch 85: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27751802.0000 - accuracy: 0.7907 - val_loss: -27332020.0000 - val_accuracy: 0.8303 - lr: 2.2487e-07\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27757850.0000 - accuracy: 0.7907\n",
      "Epoch 86: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27757850.0000 - accuracy: 0.7907 - val_loss: -27332546.0000 - val_accuracy: 0.8303 - lr: 2.0347e-07\n",
      "Epoch 87/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27733926.0000 - accuracy: 0.7892\n",
      "Epoch 87: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27750010.0000 - accuracy: 0.7907 - val_loss: -27333066.0000 - val_accuracy: 0.8303 - lr: 1.8411e-07\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27755978.0000 - accuracy: 0.7907\n",
      "Epoch 88: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27755978.0000 - accuracy: 0.7907 - val_loss: -27333122.0000 - val_accuracy: 0.8303 - lr: 1.6659e-07\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27753728.0000 - accuracy: 0.7907\n",
      "Epoch 89: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27753728.0000 - accuracy: 0.7907 - val_loss: -27334116.0000 - val_accuracy: 0.8303 - lr: 1.5073e-07\n",
      "Epoch 90/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27757538.0000 - accuracy: 0.7923\n",
      "Epoch 90: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -27746250.0000 - accuracy: 0.7907 - val_loss: -27334630.0000 - val_accuracy: 0.8303 - lr: 1.3639e-07\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27752372.0000 - accuracy: 0.7907\n",
      "Epoch 91: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27752372.0000 - accuracy: 0.7907 - val_loss: -27335538.0000 - val_accuracy: 0.8303 - lr: 1.2341e-07\n",
      "Epoch 92/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27754722.0000 - accuracy: 0.7897\n",
      "Epoch 92: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -27751584.0000 - accuracy: 0.7907 - val_loss: -27336276.0000 - val_accuracy: 0.8303 - lr: 1.1167e-07\n",
      "Epoch 93/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27760000.0000 - accuracy: 0.7902\n",
      "Epoch 93: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27756640.0000 - accuracy: 0.7907 - val_loss: -27337286.0000 - val_accuracy: 0.8303 - lr: 1.0104e-07\n",
      "Epoch 94/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27788992.0000 - accuracy: 0.7912\n",
      "Epoch 94: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -27759422.0000 - accuracy: 0.7907 - val_loss: -27338124.0000 - val_accuracy: 0.8303 - lr: 9.1424e-08\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27766284.0000 - accuracy: 0.7907\n",
      "Epoch 95: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27766284.0000 - accuracy: 0.7907 - val_loss: -27338660.0000 - val_accuracy: 0.8303 - lr: 8.2724e-08\n",
      "Epoch 96/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27789304.0000 - accuracy: 0.7912\n",
      "Epoch 96: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -27760254.0000 - accuracy: 0.7907 - val_loss: -27338654.0000 - val_accuracy: 0.8303 - lr: 7.4852e-08\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27757846.0000 - accuracy: 0.7907\n",
      "Epoch 97: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 31ms/step - loss: -27757846.0000 - accuracy: 0.7907 - val_loss: -27339186.0000 - val_accuracy: 0.8303 - lr: 6.7729e-08\n",
      "Epoch 98/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27758676.0000 - accuracy: 0.7907\n",
      "Epoch 98: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27752912.0000 - accuracy: 0.7907 - val_loss: -27339460.0000 - val_accuracy: 0.8303 - lr: 6.1283e-08\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - ETA: 0s - loss: -27759950.0000 - accuracy: 0.7907\n",
      "Epoch 99: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 30ms/step - loss: -27759950.0000 - accuracy: 0.7907 - val_loss: -27339460.0000 - val_accuracy: 0.8303 - lr: 5.5452e-08\n",
      "Epoch 100/100\n",
      "97/98 [============================>.] - ETA: 0s - loss: -27749096.0000 - accuracy: 0.7907\n",
      "Epoch 100: val_accuracy did not improve from 0.83027\n",
      "98/98 [==============================] - 3s 29ms/step - loss: -27756814.0000 - accuracy: 0.7907 - val_loss: -27339460.0000 - val_accuracy: 0.8303 - lr: 5.0175e-08\n"
     ]
    }
   ],
   "source": [
    "model,history = train_model(model, x_train, y_train,x_test, y_test, save_to= './', epoch = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35207dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4a01cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 15ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_pred \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m, dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:307\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[0;32m    223\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    224\u001b[0m ):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 307\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "y_pred =model.predict(x_test)\n",
    "y_pred = np.array(y_pred >= 0.5, dtype = np.int)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d4ada7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       ...,\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be0f5e9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2132\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[0;32m   2018\u001b[0m     y_true,\n\u001b[0;32m   2019\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2026\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2027\u001b[0m ):\n\u001b[0;32m   2028\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2029\u001b[0m \n\u001b[0;32m   2030\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2132\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2135\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe94ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
